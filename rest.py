import TkEasyGUI as sg
import requests
from bs4 import BeautifulSoup
import pdfplumber
from pysummarization.nlpbase.auto_abstractor import AutoAbstractor
from pysummarization.tokenizabledoc.simple_tokenizer import SimpleTokenizer
from pysummarization.abstractabledoc.top_n_rank_abstractor import TopNRankAbstractor

# ãƒ†ã‚­ã‚¹ãƒˆè¦ç´„é–¢æ•°
def summarize_text(text):
    print("è¦ç´„å‡¦ç†é–‹å§‹")
    auto_abstractor = AutoAbstractor()
    auto_abstractor.tokenizable_doc = SimpleTokenizer()
    abstractor = TopNRankAbstractor()

    try:
        result_dict = auto_abstractor.summarize(text, abstractor)
        summary = '\n'.join(result_dict["summarize_result"])
        print("è¦ç´„å®Œäº†:", summary)
        return summary if summary else "è¦ç´„ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        print("è¦ç´„ä¸­ã«ã‚¨ãƒ©ãƒ¼:", e)
        return "è¦ç´„ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

# PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
def extract_text_from_pdf(pdf_path):
    print("PDFè§£æé–‹å§‹:", pdf_path)
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + " "  # æ”¹è¡Œã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«å¤‰æ›
        cleaned_text = " ".join(text.split())  # ä½™åˆ†ãªç©ºç™½ã‚’å‰Šé™¤

        # âœ… ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        print("ğŸ” PDFæœ¬æ–‡ã®ä¸€éƒ¨:", cleaned_text[:1000])  # æœ€åˆã®1000æ–‡å­—ã‚’è¡¨ç¤º

        return cleaned_text if cleaned_text else "PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        print("âŒ PDFè§£æã‚¨ãƒ©ãƒ¼:", e)
        return "PDFã‚’èª­ã¿å–ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"



# Webè¨˜äº‹ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
def fetch_web_text(url):
    print("Webå–å¾—é–‹å§‹:", url)
    try:
        response = requests.get(url, headers={"User-Agent": "Mozilla/5.0"})
        soup = BeautifulSoup(response.text, 'html.parser')

        # è¨˜äº‹æœ¬æ–‡ã‚‰ã—ããƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        article = soup.find('article')
        if article:
            paragraphs = article.find_all('p')
        else:
            paragraphs = soup.find_all('p')

        text = '\n'.join([p.get_text().strip() for p in paragraphs if len(p.get_text().strip()) > 20])  # 20æ–‡å­—ä»¥ä¸Šã®æ®µè½ã‚’å–å¾—
        print("å–å¾—ã—ãŸWebè¨˜äº‹ã®å…¨æ–‡:", text[:500])

        return text if text else "Webè¨˜äº‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"
    except Exception as e:
        print("Webå–å¾—ã‚¨ãƒ©ãƒ¼:", e)
        return "Webè¨˜äº‹ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

# GUIãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    layout = [
        [sg.Text('Webè¨˜äº‹ã®URL:'), sg.InputText(key='url'), sg.Button('å–å¾—')],
        [sg.Text('PDFãƒ•ã‚¡ã‚¤ãƒ«:'), sg.InputText(key='pdf_path'), sg.FileBrowse(file_types=(('PDF Files', '*.pdf'),))],
        [sg.Button('è¦ç´„')],
        [sg.Text('ã‚¿ã‚¤ãƒˆãƒ«ãƒªã‚¹ãƒˆ:')],
        [sg.Listbox(values=[], size=(50, 10), key='title_list')],
        [sg.Text('è¦ç´„çµæœ:')],
        [sg.Multiline(size=(60, 10), key='summary')],
    ]
    
    window = sg.Window('è«–æ–‡ãƒ»è¨˜äº‹è¦ç´„ãƒ„ãƒ¼ãƒ«', layout)

    title_list = []

    while True:
        event, values = window.read()
        if event == sg.WINDOW_CLOSED:
            break
        
        if event == 'å–å¾—':
            url = values.get('url', '').strip()
            if url:
                text = fetch_web_text(url)
                if "å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ" in text:
                    window['summary'].update(text)
                    continue  # ã‚¨ãƒ©ãƒ¼ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
                
                summary = summarize_text(text)
                print("GUIã«è¡¨ç¤ºã™ã‚‹è¦ç´„:", summary)

                window['summary'].update(summary)
                window.refresh()

                title_list.append(url)
                window['title_list'].update(title_list)
                
        if event == 'è¦ç´„':
            pdf_path = values.get('pdf_path', '').strip()
            if pdf_path:
                text = extract_text_from_pdf(pdf_path)
                if "å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ" in text:
                    window['summary'].update(text)
                    continue  # ã‚¨ãƒ©ãƒ¼ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—

                summary = summarize_text(text)
                print("GUIã«è¡¨ç¤ºã™ã‚‹è¦ç´„:", summary)

                window['summary'].update(summary)
                window.refresh()

                title_list.append(pdf_path)
                window['title_list'].update(title_list)
    
    window.close()

if __name__ == "__main__":
    main()
